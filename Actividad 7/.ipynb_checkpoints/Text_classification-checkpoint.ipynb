{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ic4_occAAiAT"
   },
   "source": [
    "##### Copyright 2018 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "ioaprt5q5US7"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "yCl0eTNH5RS3"
   },
   "outputs": [],
   "source": [
    "#@title MIT License\n",
    "#\n",
    "# Copyright (c) 2017 François Chollet\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a\n",
    "# copy of this software and associated documentation files (the \"Software\"),\n",
    "# to deal in the Software without restriction, including without limitation\n",
    "# the rights to use, copy, modify, merge, publish, distribute, sublicense,\n",
    "# and/or sell copies of the Software, and to permit persons to whom the\n",
    "# Software is furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL\n",
    "# THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING\n",
    "# FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER\n",
    "# DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ItXfxkxvosLH"
   },
   "source": [
    "# Text classification with movie reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKY4XMc9o8iB"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://www.tensorflow.org/tutorials/keras/basic_text_classification\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/r2.0rc/site/en/tutorials/keras/basic_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/r2.0rc/site/en/tutorials/keras/basic_text_classification.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eg62Pmz3o83v"
   },
   "source": [
    "Alumno: Manuel de Jesus Rios Guardado - 17130110\n",
    "\n",
    "En este cuaderno se clasifican las evaluaciones de usuarios a películas como *positivas* o *negativas*. Este es un ejeplo de una clasificación *binaria* o de dos clases, un problema ampliamente aplicable en el aprendizaje automático.\n",
    "\n",
    "Se usará el conjunto de datos de [IMDB](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/imdb) que contiene el texto de 50,000 evaluaciones de películas de la Internet Movie DataBase (IMBD). Este conjunto se divide en 25,000 evaluaciones para el entrenamiento y 25,000 para la prueba. Los conjuntos de entrenamiento y prueba estan *balanceados*, lo que significa que ambos contienen la misma cantidad de evaluaciones positivas y negativas.\n",
    "\n",
    "Este cuaderno usa [tf.keras](https://www.tensorflow.org/guide/keras), una API de alto nivel para entrenar modelos en TensorFlow. Para un tutorial más avanzado en clasificación de texto usando `tf.keras`, ve a [MLCC Text Classification Guide](https://developers.google.com/machine-learning/guides/text-classification/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JL-LtD0CBSZR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_nightly in c:\\users\\manue\\anaconda3\\lib\\site-packages (2.7.0.dev20210627)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (3.7.4.3)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (0.36.2)\n",
      "Requirement already satisfied: tf-estimator-nightly~=2.6.0.dev in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (2.6.0.dev2021062501)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (3.17.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (3.1.0)\n",
      "Requirement already satisfied: tb-nightly~=2.6.0.a in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (2.6.0a20210626)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.1.2)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.6.3)\n",
      "Requirement already satisfied: absl-py~=0.10 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (0.13.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.12.1)\n",
      "Requirement already satisfied: clang~=5.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (5.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (3.3.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.19.5)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (1.38.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.15.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (1.12)\n",
      "Requirement already satisfied: keras-nightly~=2.6.0.dev in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tf_nightly) (2.6.0.dev2021062500)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tf_nightly) (0.4.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (1.32.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (2.25.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (52.0.0.post20210125)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (1.8.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from tb-nightly~=2.6.0.a->tf_nightly) (0.4.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf_nightly) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf_nightly) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf_nightly) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf_nightly) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly~=2.6.0.a->tf_nightly) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf_nightly) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf_nightly) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf_nightly) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\manue\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tb-nightly~=2.6.0.a->tf_nightly) (4.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\manue\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly~=2.6.0.a->tf_nightly) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "# keras.datasets.imdb is broken in 1.13 and 1.14, by np 1.16.3\n",
    "!pip install tf_nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ew7HTbPpCJH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iAsKG535pHep"
   },
   "source": [
    "## Descargar el conjunto de datos IMDB\n",
    "\n",
    "El conjunto de datos IMDB viene incluido con TensorFlow. Ya ha sido preprocesado de tal forma que las evaluaciones (secuencias de palabras) se han convertido a secuencias de enteros, donde cada entero representa una palabra específica en un diccionario.\n",
    "\n",
    "El siguiente código descarga el conjunto de datos IMDB a tu máquina (o usa una copia del caché si ya lo descargaste):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zXXx5Oc3pOmN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 3s 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "C:\\Users\\manue\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\manue\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "imdb = keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "odr-KlzO-lkL"
   },
   "source": [
    "El argumento `num_words=10000` mantiene las 10,000 palabras más frecuentes que ocurren en el conjunto de datos de entrenamiento. Las palabras raras se descartan para mantener manejabla el tamaño de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l50X3GfjpU4r"
   },
   "source": [
    "## Exploración de los datos\n",
    "\n",
    "Nos tomaremos un momento para entender el formato de los datos. el conjunto de datos esta preprocesado: cada ejemplo en el arreglo de enteros representa a las palabras de la evaluación de las películas. Cada etiqueta es un valor entero ya se de 0 o 1, donde 0 es una evaluación negativa y 1 es una evaluación positiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8qCnve_-lkO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training entries: 25000, labels: 25000\n"
     ]
    }
   ],
   "source": [
    "print(\"Training entries: {}, labels: {}\".format(len(train_data), len(train_labels)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnKvHWW4-lkW"
   },
   "source": [
    "El texto de las evaluaciones se ha convertido a enteros, donde cada entero representa una palabra específica en un diccionario. Así es como se ve la primera evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtTS4kpEpjbi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hIE4l_72x7DP"
   },
   "source": [
    "Las evaluaciones de las películas pueden tener distinta cantidad de palabras. En el código de abajo se muestra el número de palabras en la primera y segunda evaluación. \n",
    "Ya que las entradas a las redes neuronales deben tener el mismo tamaño, tendremos que resolver esto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-6Ii9Pfx6Nr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(218, 189)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4wJg2FiYpuoX"
   },
   "source": [
    "### Convertir los enteros de nuevo a palabras\n",
    "\n",
    "Puede ser útil convertir los enteros nuevamente a texto. En el siguiente código creamos una función de ayuda para buscar las palabras en un diccionario que contiene los enteros para mapearlos al texto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tr5s_1alpzop"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Un diccionario que mapea las palabras a un índice entero\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# Los primeros índices están reservados\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "    return ' '.join([reverse_word_index.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "U3CNRvEZVppl"
   },
   "source": [
    "Ahora podemos usar la función `decode_review` para desplegar el texto para la primera evaluación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s_OqxmH6-lkn"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFP_XKVRp4_S"
   },
   "source": [
    "## Preparar los datos\n",
    "\n",
    "Los arreglos con las evaluaciones que contienen los enteros deben de convertirse a tensores antes de usarse para introducirse a las redes neuronales. Esta conversión se puede hacer de dos formas:\n",
    "\n",
    "* Convertir los arreglos en vectores con 0s y 1s que indican que palabras de un diccionario ocurren en una evaluación, similar a lo que se conoce como one-hot enoding. Por ejemplo, la secuencia [3, 5] se convertería un vector con 10,000 elementos que estaría lleno de ceros, excepto en los índices 3 y 5 que se refiere a las palabras que ocurren. Entonces, esto sería la primera capa de la red neuronal. Esta forma requiere bastante memoria, ya que requiere una matriz de `num_words * num_reviews`.\n",
    "\n",
    "* Alternativamente, podemos hacer padding (o rellenar) los arreglos de forma que todos tengan la misma longitud, después crear un tensor de enteros con una forma `max_length * num_reviews`. Podemos usar una capa embebida capaz de manejar esta forma como la primer capa de la red.\n",
    "\n",
    "En este tutorial, usaremos la segunda forma.\n",
    "\n",
    "\n",
    "Ya que las evaluaciones de las películas deben tener la misma longitud, usaremos la función [pad_sequences](https://keras.io/preprocessing/sequence/#pad_sequences) para estandarizar las longitudes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2jQv-omsHurp"
   },
   "outputs": [],
   "source": [
    "train_data = keras.preprocessing.sequence.pad_sequences(train_data,\n",
    "                                                        value=word_index[\"<PAD>\"],\n",
    "                                                        padding='post',\n",
    "                                                        maxlen=256)\n",
    "\n",
    "test_data = keras.preprocessing.sequence.pad_sequences(test_data,\n",
    "                                                       value=word_index[\"<PAD>\"],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VO5MBpyQdipD"
   },
   "source": [
    "Vamos a ver la longitud de los ejemplos ahora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "USSSBnkE-lky"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0]), len(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QJoxZGyfjT5V"
   },
   "source": [
    "E inspeccionar la primera evaluación (ahora rellenada):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG8X9cqi-lk9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   1   14   22   16   43  530  973 1622 1385   65  458 4468   66 3941\n",
      "    4  173   36  256    5   25  100   43  838  112   50  670    2    9\n",
      "   35  480  284    5  150    4  172  112  167    2  336  385   39    4\n",
      "  172 4536 1111   17  546   38   13  447    4  192   50   16    6  147\n",
      " 2025   19   14   22    4 1920 4613  469    4   22   71   87   12   16\n",
      "   43  530   38   76   15   13 1247    4   22   17  515   17   12   16\n",
      "  626   18    2    5   62  386   12    8  316    8  106    5    4 2223\n",
      " 5244   16  480   66 3785   33    4  130   12   16   38  619    5   25\n",
      "  124   51   36  135   48   25 1415   33    6   22   12  215   28   77\n",
      "   52    5   14  407   16   82    2    8    4  107  117 5952   15  256\n",
      "    4    2    7 3766    5  723   36   71   43  530  476   26  400  317\n",
      "   46    7    4    2 1029   13  104   88    4  381   15  297   98   32\n",
      " 2071   56   26  141    6  194 7486   18    4  226   22   21  134  476\n",
      "   26  480    5  144   30 5535   18   51   36   28  224   92   25  104\n",
      "    4  226   65   16   38 1334   88   12   16  283    5   16 4472  113\n",
      "  103   32   15   16 5345   19  178   32    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLC02j2g-llC"
   },
   "source": [
    "## Construir el modelo\n",
    "\n",
    "La red neuronal se crea al apilar capas, lo que requiero dos decisiones de arquitectura principales:\n",
    "\n",
    "* ¿Cuántas capas se usarán en el modelo?\n",
    "* ¿Cuántas *hidden units* (unidades ocultas) se usarán en cada capa?\n",
    "\n",
    "En este ejemplo, los datos de entrada consisten en un arreglo con índices de palabras. Las etiquetas para la predicción son ya sea 0 o 1. Vamos a construir un modelo para este problema:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xpKOoWgu-llD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d (Gl (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 160,289\n",
      "Trainable params: 160,289\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# la forma de la entrada es el contador del vocabulario usado para las evaluaciones de las pelícuas (10,000 palabras)\n",
    "vocab_size = 10000\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation=tf.nn.relu))\n",
    "model.add(keras.layers.Dense(1, activation=tf.nn.sigmoid))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PbKQ6mucuKL"
   },
   "source": [
    "Las capas estan apiladas de forma secuencial para construir al clasificador:\n",
    "\n",
    "1. La primera capa es una capa `Embebida`. Esta capa toma el vocabulario de enteros codificados y busca el vector embebido para cada indice de palabra. Estos datos se aprende conforme el modelo se entrena. Los vector agregan una dimensión al arreglo de salida. La dimensión resultante es:>\n",
    "\n",
    "1. The layers are stacked sequentially to build the classifier:`(batch, sequence, embedding)`.\n",
    "2. A una capa llamada `GlobalAveragePooling1D`  regresa un vector de salida con un tamaño fijo para caad ejemplo, promediando sobre la dimensión de la secuencia. Esto permite al modelo la capacidad de manipular la longitud de la variable de entrada, de la manera más fácil posible.\n",
    "3. Este vector de tamaño fijo se conduce a través de una capa completamente conectada (`Dense`) con 16 unidades escondidas.\n",
    "4. La última capa es una capa densamiente conectada con solo un nodo de salida. Por medio de la función de activación `sigmoid`, este valor fluctúa entre 0 y 1, representando una probabilidad o nivel de confianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0XMwnDOp-llH"
   },
   "source": [
    "### Unidades ocultas\n",
    "\n",
    "El modelo tiene dos capas intermedias \"ocultas\", entre las capas de entrada y de salida. el número de salidas (unidades, nodos, o neuronas) es la dimensión del espacio de representación para cada capa. En otras palabras, la cantidad de libertad de la red esta permitida cuando se aprende una representación interna.\n",
    "\n",
    "Si un modelo tiene más unidades ocultas (un espacio de representación de dimensión mas alta), u otro con mas capas. entonces la red puede aprender representaciones más complejas. Sin emabrgo, esto provoca que la red requiere más recursos computacionales y podría llegar a aprender patrones no deseados que mejoran el desempeño en los datos de entrenamiento pero no en los datos de prueba, a esto se le conoce como *overfitting* y se verá mas adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L4EqVWg4-llM"
   },
   "source": [
    "### Optimizador y función de pérdida\n",
    "\n",
    "Un modelo necesita una función de pérdida y un optimizador para el entrenamiento. Ya que es un problema de clasificación binaria, y el modelo entrega una probabilidad como salida (una capa con un solo nodo con una función de activación sigmoide(, usaremos la función de pérdida `binary_crossentropy`.\n",
    "\n",
    "Este no es la única decisión respecto a la función de pérdida, se puede, por ejemplo, escoger `mean_squared_error`. Pero, generalmente la `binary_crossentropy` es mejor para tratar con probabilidades, ya que mide la \"distancia\"entre las distribuciones de probabilidad, o en nuestro caso, entre la distribución de nuestro \"ground-truth\" y las predicciones.\n",
    "\n",
    "Ahora, configuramos el modelo para usar un optimizador y una función de pérdida:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Mr0GP-cQ-llN"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hCWYwkug-llQ"
   },
   "source": [
    "## Creación de un conjunto de validación\n",
    "\n",
    "Cuando entrenamos, queremos checar la exactitud del modelo en datos que no ha visto nunca. Creamos un *conjunto de validación* al separar 10,000 ejemplos del conjunto de datos de entrenamiento original. (Porqué no solo usar el conjunto de prueba de una vez? Nuestra meta es desarrollar y ajustar nuestro modelos usando únicamente datos de entrenamiento, y después usar datos de prueba solo una vez para evaluar nuestra exactitud)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NpcXY9--llS"
   },
   "outputs": [],
   "source": [
    "x_val = train_data[:10000]\n",
    "partial_x_train = train_data[10000:]\n",
    "\n",
    "y_val = train_labels[:10000]\n",
    "partial_y_train = train_labels[10000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "35jv_fzP-llU"
   },
   "source": [
    "## Entrenamiento del modelo\n",
    "\n",
    "Entrar el modelo por 40 époas en mini-lotes de 512 ejemplos. Esto es, 40 iteraciones sobre todas las muestras de tensores `x_train` y `y_train`. Mientras se entrena, se monitorea la pérdida y exactitud en las 10,000 muestras del conjunto de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tXSGrjWZ-llW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 0.6918 - acc: 0.6182 - val_loss: 0.6898 - val_acc: 0.7094\n",
      "Epoch 2/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.6863 - acc: 0.7335 - val_loss: 0.6825 - val_acc: 0.7167\n",
      "Epoch 3/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.6744 - acc: 0.7415 - val_loss: 0.6681 - val_acc: 0.7036\n",
      "Epoch 4/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.6539 - acc: 0.7534 - val_loss: 0.6443 - val_acc: 0.7575\n",
      "Epoch 5/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.6241 - acc: 0.7792 - val_loss: 0.6131 - val_acc: 0.7712\n",
      "Epoch 6/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5868 - acc: 0.7957 - val_loss: 0.5764 - val_acc: 0.7925\n",
      "Epoch 7/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.5441 - acc: 0.8195 - val_loss: 0.5363 - val_acc: 0.8093\n",
      "Epoch 8/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.4988 - acc: 0.8366 - val_loss: 0.4952 - val_acc: 0.8241\n",
      "Epoch 9/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4547 - acc: 0.8516 - val_loss: 0.4578 - val_acc: 0.8375\n",
      "Epoch 10/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.4153 - acc: 0.8645 - val_loss: 0.4254 - val_acc: 0.8456\n",
      "Epoch 11/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3809 - acc: 0.8761 - val_loss: 0.3993 - val_acc: 0.8523\n",
      "Epoch 12/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3521 - acc: 0.8825 - val_loss: 0.3775 - val_acc: 0.8586\n",
      "Epoch 13/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.3281 - acc: 0.8899 - val_loss: 0.3599 - val_acc: 0.8645\n",
      "Epoch 14/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.3067 - acc: 0.8970 - val_loss: 0.3457 - val_acc: 0.8690\n",
      "Epoch 15/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2887 - acc: 0.9018 - val_loss: 0.3342 - val_acc: 0.8719\n",
      "Epoch 16/40\n",
      "30/30 [==============================] - 0s 17ms/step - loss: 0.2728 - acc: 0.9063 - val_loss: 0.3252 - val_acc: 0.8731\n",
      "Epoch 17/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2587 - acc: 0.9111 - val_loss: 0.3165 - val_acc: 0.8777\n",
      "Epoch 18/40\n",
      "30/30 [==============================] - 1s 18ms/step - loss: 0.2458 - acc: 0.9160 - val_loss: 0.3101 - val_acc: 0.8786\n",
      "Epoch 19/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2341 - acc: 0.9194 - val_loss: 0.3048 - val_acc: 0.8793\n",
      "Epoch 20/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2233 - acc: 0.9237 - val_loss: 0.3007 - val_acc: 0.8795\n",
      "Epoch 21/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.2133 - acc: 0.9259 - val_loss: 0.2964 - val_acc: 0.8817\n",
      "Epoch 22/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.2045 - acc: 0.9299 - val_loss: 0.2934 - val_acc: 0.8832\n",
      "Epoch 23/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1957 - acc: 0.9333 - val_loss: 0.2910 - val_acc: 0.8837\n",
      "Epoch 24/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1874 - acc: 0.9369 - val_loss: 0.2894 - val_acc: 0.8842\n",
      "Epoch 25/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1802 - acc: 0.9407 - val_loss: 0.2883 - val_acc: 0.8848\n",
      "Epoch 26/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1728 - acc: 0.9436 - val_loss: 0.2867 - val_acc: 0.8844\n",
      "Epoch 27/40\n",
      "30/30 [==============================] - 1s 20ms/step - loss: 0.1659 - acc: 0.9475 - val_loss: 0.2864 - val_acc: 0.8847\n",
      "Epoch 28/40\n",
      "30/30 [==============================] - 1s 19ms/step - loss: 0.1594 - acc: 0.9497 - val_loss: 0.2856 - val_acc: 0.8849\n",
      "Epoch 29/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1534 - acc: 0.9533 - val_loss: 0.2858 - val_acc: 0.8858\n",
      "Epoch 30/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1478 - acc: 0.9543 - val_loss: 0.2866 - val_acc: 0.8858\n",
      "Epoch 31/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1421 - acc: 0.9563 - val_loss: 0.2881 - val_acc: 0.8842\n",
      "Epoch 32/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1371 - acc: 0.9593 - val_loss: 0.2883 - val_acc: 0.8860\n",
      "Epoch 33/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1316 - acc: 0.9614 - val_loss: 0.2897 - val_acc: 0.8855\n",
      "Epoch 34/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1274 - acc: 0.9619 - val_loss: 0.2914 - val_acc: 0.8857\n",
      "Epoch 35/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1224 - acc: 0.9647 - val_loss: 0.2924 - val_acc: 0.8853\n",
      "Epoch 36/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1182 - acc: 0.9663 - val_loss: 0.2942 - val_acc: 0.8857\n",
      "Epoch 37/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1137 - acc: 0.9683 - val_loss: 0.2967 - val_acc: 0.8853\n",
      "Epoch 38/40\n",
      "30/30 [==============================] - 0s 16ms/step - loss: 0.1093 - acc: 0.9697 - val_loss: 0.2985 - val_acc: 0.8860\n",
      "Epoch 39/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1054 - acc: 0.9709 - val_loss: 0.3010 - val_acc: 0.8847\n",
      "Epoch 40/40\n",
      "30/30 [==============================] - 1s 17ms/step - loss: 0.1018 - acc: 0.9727 - val_loss: 0.3068 - val_acc: 0.8810\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=40,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9EEGuDVuzb5r"
   },
   "source": [
    "## Evaluar el modelo\n",
    "\n",
    "Veamos como se desempeña el modelo. Se regresan dos valores. La pérdida (un número que representa nuestro error, valores más bajos son mejores), y exactitud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zOMKywn4zReN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 718us/step - loss: 0.3247 - acc: 0.8714\n",
      "[0.32466739416122437, 0.8714399933815002]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z1iEXVTR0Z2t"
   },
   "source": [
    "Esta propuesta, que es algo ingenua, logra una exactitud de 87%. Con propuestas de arquitecturas más avanzadas, el modelo puede incrementar a cerca de 95%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5KggXVeL-llZ"
   },
   "source": [
    "## Crear un gráfica de exactitud y pérdida a través del tiempo\n",
    "\n",
    "`model.fit()` regresa un objeto `History` que contiene un diccionario con todo lo que sucedió durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VcvSXvhp-llb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nRKsqL40-lle"
   },
   "source": [
    "Hay cuantro entradas: una para cada medida monitoreada durante el entrenamiento y validación. Esamos estos valores para graficar y comparar la pérdida y exactitud en el entrenamiento y validación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGoYf2Js-lle"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['acc']\n",
    "val_acc = history_dict['val_acc']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6hXx-xOv-llh"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # clear figure\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oFEmZ5zq-llk"
   },
   "source": [
    "En esta gráfica, los puntos representan la pérdida y la exactitud en el entrenamiento mientras que la linea sólida representa la pérdida y exactitud en la validación.\n",
    "\n",
    "Nota que la pérdida *disminuye* en cada época durante el entrenamiento y la exactitud *incremementa* con cada época. Esto es esperado la que cuando se usa el algoritmo de optimización del descenso del grandiente se debe minimizar la cantidad deseada sobre cada iteración.\n",
    "\n",
    "Esto no es el caso para la périda y la exactitud en la validación, ya que se ven que llegan a un pico en las 20 épocas. Este es un ejemplo de *overfitting*: el modelo funciona mejor en los datos de entremaiento que en datos que no ha visto nunca. Después de este punto, el modelo sobre-optimiza y encuentra representaciones *específicas* para los datos de entrenamiento que no *generalizan* a los datos de prueba.\n",
    "\n",
    "Para este caso particular, podemos prevenir el *overfitting* al parar el entrenamiento después de las 20 épocas.\n",
    "\n",
    "## Predecir una evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability:  [[0.9988227]]\n",
      "Label predicted:  1\n",
      "Evaluación:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"a lot of patience because it focuses on mood and character development the plot is very simple and many of the scenes take place on the same set in frances <UNK> the sandy dennis character apartment but the film builds to a disturbing climax br br the characters create an atmosphere <UNK> with sexual tension and psychological <UNK> it's very interesting that robert altman directed this considering the style and structure of his other films still the trademark altman audio style is evident here and there i think what really makes this film work is the brilliant performance by sandy dennis it's definitely one of her darker characters but she plays it so perfectly and convincingly that it's scary michael burns does a good job as the mute young man regular altman player michael murphy has a small part the <UNK> moody set fits the content of the story very well in short this movie is a powerful study of loneliness sexual <UNK> and desperation be patient <UNK> up the atmosphere and pay attention to the wonderfully written script br br i praise robert altman this is one of his many films that deals with unconventional fascinating subject matter this film is disturbing but it's sincere and it's sure to <UNK> a strong emotional response from the viewer if you want to see an unusual film some might even say bizarre this is worth the time br br unfortunately it's very difficult to find in video stores you may have to buy it off the internet\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.predict(test_data[[1]])\n",
    "print(\"Probability: \", results)\n",
    "print(\"Label predicted: \",test_labels[1])\n",
    "print(\"Evaluación:\")\n",
    "decode_review(test_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostrar palabras del diccionario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fawn', 'tsukino', 'nunnery', 'sonja', 'vani', 'woods', 'spiders', 'hanging', 'woody', 'trawling']\n"
     ]
    }
   ],
   "source": [
    "print(list(word_index.keys())[0:10])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "basic-text-classification.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
